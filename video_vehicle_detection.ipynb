{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vehicle Detection Using HOG+SVM Classifier\n",
    "===\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "#import pickle\n",
    "from find_cars import *\n",
    "from lesson_functions import draw_boxes\n",
    "\n",
    "import imageio\n",
    "#imageio.plugins.ffmpeg.download()\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_scaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'cell_per_block': 2,\n",
       " 'color_space': 'YCrCb',\n",
       " 'hist_bins': 32,\n",
       " 'hist_feat': True,\n",
       " 'hog_channel': 'ALL',\n",
       " 'hog_feat': True,\n",
       " 'orient': 9,\n",
       " 'pix_per_cell': 8,\n",
       " 'spatial_feat': True,\n",
       " 'spatial_size': (32, 32),\n",
       " 'svc': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "      intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "      multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "      verbose=0)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_ind = 0;\n",
    "pickle_file = \"HOGClassifier.p\"\n",
    "load_classifier(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tuning & saving heatmaps\n",
    "avgBoxes = BoundingBoxes(10)\n",
    "\n",
    "def process_image(image):\n",
    "    global frame_ind    \n",
    "    frame_ind += 1\n",
    "    result = process_image_hog_pipeline(image, frame_ind, useHeatmap=True, thresh=1,\n",
    "                                        avgBoxes=avgBoxes, verbose=True, verboseSaveHeatmaps=True)      \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate final version\n",
    "avgBoxes = BoundingBoxes(10)\n",
    "verbose = True\n",
    "\n",
    "def process_image(image):\n",
    "    global frame_ind\n",
    "    global avgBoxes\n",
    "    global verbose\n",
    "    \n",
    "    frame_ind += 1\n",
    "    \n",
    "    result = process_image_hog_pipeline(image, frame_ind, useHeatmap=True, thresh=29,\n",
    "                                        avgBoxes=avgBoxes, verbose=verbose, verboseSaveHeatmaps=False)      \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./output_images/processed_project_video.mp4\n",
      "[MoviePy] Writing video ./output_images/processed_project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [18:42<00:01,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./output_images/processed_project_video.mp4 \n",
      "\n",
      "Wall time: 18min 43s\n"
     ]
    }
   ],
   "source": [
    "frame_ind = 0\n",
    "out_dir='./output_images/'\n",
    "output = out_dir + 'processed_project_video.mp4'\n",
    "clip = VideoFileClip(\"project_video.mp4\")\n",
    "#output = out_dir + 'processed_test_video.mp4'\n",
    "#clip = VideoFileClip(\"test_video.mp4\")\n",
    "out_clip = clip.fl_image(process_image) \n",
    "%time out_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Grid detection on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame_ind = 0;\n",
    "\n",
    "def process_image_grid(img):\n",
    "    global frame_ind\n",
    "    frame_ind += 1\n",
    "    \n",
    "    ystart = 400\n",
    "    ystop = 656\n",
    "    scale = 1\n",
    "    \n",
    "    #bboxes = find_cars_grid_160(img)\n",
    "    #img = draw_boxes(img, bboxes, color=(0, 255, 255), thick=10)\n",
    "    \n",
    "    #bboxes = find_cars_grid_128(img)\n",
    "    #img = draw_boxes(img, bboxes, color=(0, 0, 255), thick=8)\n",
    "\n",
    "    #bboxes = find_cars_grid_96(img)\n",
    "    #img = draw_boxes(img, bboxes, color=(0, 255, 0), thick=4)\n",
    "\n",
    "    # Scale 1\n",
    "#    bboxes = find_cars_grid_1(img)\n",
    "#    result = draw_boxes(img, bboxes, color=(0, 0, 255), thick=4)\n",
    "#    bboxes = find_cars_grid_1(img, cells_per_step=2)\n",
    "#    result = draw_boxes(result, bboxes, color=(255, 0, 0), thick=1)\n",
    "\n",
    "    # Scale 2\n",
    "#    bboxes = find_cars_grid_2(img)\n",
    "#    result = draw_boxes(img, bboxes, color=(0, 0, 255), thick=4)\n",
    "#    bboxes = find_cars_grid_2(img, cells_per_step=2)\n",
    "#    result = draw_boxes(result, bboxes, color=(255, 0, 0), thick=1)\n",
    "\n",
    "    # Scale 3\n",
    "    bboxes = find_cars_grid_3(img)\n",
    "    result = draw_boxes(img, bboxes, color=(0, 0, 255), thick=4)\n",
    "    bboxes = find_cars_grid_3(img, cells_per_step=2)\n",
    "    result = draw_boxes(result, bboxes, color=(255, 0, 0), thick=1)\n",
    "    \n",
    "    \n",
    "    # add frame_index text at the bottom of board\n",
    "    xmax = 800\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(result, 'frame {:d}'.format(frame_ind), (xmax + 20, 60), font, 0.9, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./grid_project_video.mp4\n",
      "[MoviePy] Writing video ./grid_project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [00:20<00:00, 60.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./grid_project_video.mp4 \n",
      "\n",
      "Wall time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "out_dir='./'\n",
    "output = out_dir + 'grid_project_video.mp4'\n",
    "clip = VideoFileClip(\"project_video.mp4\")\n",
    "#output = out_dir + 'grid_challenge_video.mp4'\n",
    "#clip = VideoFileClip(\"challenge_video.mp4\")\n",
    "out_clip = clip.fl_image(process_image_grid) \n",
    "%time out_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Extraction frames from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "out_dir='./temp_data/frames/project_video/'\n",
    "frame_n = 0\n",
    "\n",
    "def extract_all_frames(img):\n",
    "    global out_dir\n",
    "    global frame_n    \n",
    "    frame_n += 1\n",
    "    file_path = out_dir + str(frame_n) + '.jpg'\n",
    "    #print(file_path)\n",
    "    mpimg.imsave(file_path, img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./temp_data/tmp_video.mp4\n",
      "[MoviePy] Writing video ./temp_data/tmp_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [04:48<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./temp_data/tmp_video.mp4 \n",
      "\n",
      "Wall time: 4min 49s\n"
     ]
    }
   ],
   "source": [
    "output = './temp_data/' + 'tmp_video.mp4'\n",
    "clip = VideoFileClip(\"project_video.mp4\")\n",
    "out_clip = clip.fl_image(extract_all_frames) \n",
    "%time out_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
