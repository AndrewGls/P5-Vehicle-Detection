{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train HOG Classifier\n",
    "===\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lesson_functions import *\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load splitted data sets from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the training validation and test data\n",
    "data_file = 'data.p'\n",
    "with open(data_file, mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "cars_train = data['cars_train']\n",
    "cars_val   = data['cars_val']\n",
    "cars_test  = data['cars_test']\n",
    "notcars_train = data['notcars_train']\n",
    "notcars_val   = data['notcars_val']\n",
    "notcars_test  = data['notcars_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in cars training set:  6154\n",
      "Number of samples in cars validation set:  1758\n",
      "Number of samples in cars test set:  880\n",
      "Number of samples in notcars training set:  6277\n",
      "Number of samples in notcars validation set:  1794\n",
      "Number of samples in notcars test set:  897\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples in cars training set: ', len(cars_train))\n",
    "print('Number of samples in cars validation set: ', len(cars_val))\n",
    "print('Number of samples in cars test set: ', len(cars_test))\n",
    "\n",
    "print('Number of samples in notcars training set: ', len(notcars_train))\n",
    "print('Number of samples in notcars validation set: ', len(notcars_val))\n",
    "print('Number of samples in notcars test set: ', len(notcars_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two classes are quite balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in cars set:  8792\n",
      "Number of samples in notcars set:  8968\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples in cars set: ', len(cars_train)+len(cars_val)+len(cars_test))\n",
    "print('Number of samples in notcars set: ', len(notcars_train)+len(notcars_val)+len(notcars_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Extract features from image files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        # Read in each one by one\n",
    "        img = mpimg.imread(file)\n",
    "        \n",
    "        img_features = single_img_features(img, color_space=color_space, spatial_size=spatial_size,\n",
    "                        hist_bins=hist_bins, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "                        spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "    \n",
    "        features.append(img_features)\n",
    "        \n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.83 second to extract features (HOG,spatial and color features).\n"
     ]
    }
   ],
   "source": [
    "color_space = 'HLS' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16) # Spatial binning dimensions\n",
    "hist_bins = 32    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "cars_train_feats = extract_features(cars_train, color_space, spatial_size, hist_bins, orient,\n",
    "                                      pix_per_cell, cell_per_block, hog_channel, spatial_feat, hist_feat, hog_feat)\n",
    "notcars_train_feats = extract_features(notcars_train, color_space, spatial_size, hist_bins, orient,\n",
    "                                         pix_per_cell, cell_per_block, hog_channel, spatial_feat, hist_feat, hog_feat)\n",
    "\n",
    "cars_val_feats = extract_features(cars_val, color_space, spatial_size, hist_bins, orient,\n",
    "                                      pix_per_cell, cell_per_block, hog_channel, spatial_feat, hist_feat, hog_feat)\n",
    "notcars_val_feats = extract_features(notcars_val, color_space, spatial_size, hist_bins, orient,\n",
    "                                         pix_per_cell, cell_per_block, hog_channel, spatial_feat, hist_feat, hog_feat)\n",
    "\n",
    "cars_test_feats = extract_features(cars_test, color_space, spatial_size, hist_bins, orient,\n",
    "                                      pix_per_cell, cell_per_block, hog_channel, spatial_feat, hist_feat, hog_feat)\n",
    "notcars_test_feats = extract_features(notcars_test, color_space, spatial_size, hist_bins, orient,\n",
    "                                         pix_per_cell, cell_per_block, hog_channel, spatial_feat, hist_feat, hog_feat)\n",
    "\n",
    "t2 = time.time()\n",
    "print(round(t2-t1, 2), 'second to extract features (HOG,spatial and color features).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine and Normalize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((cars_train_feats, cars_val_feats, cars_test_feats,\n",
    "                  notcars_train_feats, notcars_val_feats, notcars_test_feats)).astype(np.float64)\n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set:  12431\n",
      "Number of samples in validation set:  3552\n",
      "Number of samples in test set:  1777\n"
     ]
    }
   ],
   "source": [
    "assert(len(cars_train_feats) == len(cars_train))\n",
    "assert(len(cars_val_feats) == len(cars_val))\n",
    "assert(len(cars_test_feats) == len(cars_test))\n",
    "\n",
    "assert(len(notcars_train_feats) == len(notcars_train))\n",
    "assert(len(notcars_val_feats) == len(notcars_val))\n",
    "assert(len(notcars_test_feats) == len(notcars_test))\n",
    "\n",
    "n_cars_train = len(cars_train)\n",
    "n_cars_val   = len(cars_val)\n",
    "n_cars_test  = len(cars_test)\n",
    "\n",
    "n_notcars_train = len(notcars_train)\n",
    "n_notcars_val   = len(notcars_val)\n",
    "n_notcars_test  = len(notcars_test)\n",
    "\n",
    "c1 = n_cars_train\n",
    "c2 = c1 + n_cars_val\n",
    "c3 = c2 + n_cars_test\n",
    "nc4 = c3 + n_notcars_train\n",
    "nc5 = nc4 + n_notcars_val\n",
    "\n",
    "cars_train_feats, cars_val_feats, cars_test_feats = scaled_X[:c1], scaled_X[c1:c2], scaled_X[c2:c3]\n",
    "notcars_train_feats, notcars_val_feats, notcars_test_feats = scaled_X[c3:nc4], scaled_X[nc4:nc5], scaled_X[nc5:]\n",
    "\n",
    "assert(len(cars_train_feats) == n_cars_train)\n",
    "assert(len(cars_val_feats) == n_cars_val)\n",
    "assert(len(cars_test_feats) == n_cars_test)\n",
    "\n",
    "assert(len(notcars_train_feats) == n_notcars_train)\n",
    "assert(len(notcars_val_feats) == n_notcars_val)\n",
    "assert(len(notcars_test_feats) == n_notcars_test)\n",
    "\n",
    "X_train = np.vstack((cars_train_feats, notcars_train_feats))\n",
    "X_val = np.vstack((cars_val_feats, notcars_val_feats))\n",
    "X_test = np.vstack((cars_test_feats, notcars_test_feats))\n",
    "\n",
    "# Define the labels vector\n",
    "y_train = np.hstack((np.ones(n_cars_train), np.zeros(n_notcars_train)))\n",
    "y_val = np.hstack((np.ones(n_cars_val), np.zeros(n_notcars_val)))\n",
    "y_test = np.hstack((np.ones(n_cars_test), np.zeros(n_notcars_test)))\n",
    "       \n",
    "assert(len(X_train) == len(y_train))\n",
    "assert(len(X_val) == len(y_val))\n",
    "assert(len(X_test) == len(y_test))\n",
    "\n",
    "print('Number of samples in training set: ', len(X_train))\n",
    "print('Number of samples in validation set: ', len(X_val))\n",
    "print('Number of samples in test set: ', len(X_test))\n",
    "\n",
    "# Shuffle samples in set\n",
    "random_state = 13\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=random_state)\n",
    "X_val, y_val = shuffle(X_val, y_val, random_state=random_state)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector length: 6156\n",
      "13.88 Seconds to train SVC...\n",
      "Validation Accuracy of SVC =  0.9735\n",
      "My SVC predicts:  [ 0.  1.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  0.  0.  1.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.\n",
      "  1.  1.  1.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.\n",
      "  1.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.  0.  1.  0.  0.  0.  1.\n",
      "  1.  1.  1.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  0.  0.  1.  0.  1.\n",
      "  1.  0.  1.  1.  1.  1.  1.  0.  1.  0.]\n",
      "For these 100 labels:  [ 0.  1.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.\n",
      "  1.  1.  1.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  0.\n",
      "  1.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.  0.  1.  0.  0.  0.  1.\n",
      "  1.  1.  1.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.\n",
      "  1.  0.  1.  1.  0.  1.  1.  0.  1.  0.]\n",
      "0.0 Seconds to predict 100 labels with SVC\n"
     ]
    }
   ],
   "source": [
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Validation Accuracy of SVC = ', round(svc.score(X_val, y_val), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 100\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
